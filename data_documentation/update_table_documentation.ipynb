{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Table Documentation\n",
    "\n",
    "This file takes the docs in the folder `data_documentation` and adds them to bigquery and to gcs. The markdown file in `data_documentation` must have the same name as the file in bigquery at `global-fishing-watch:global-footprint-of-fisheries.TABLE_NAME`. Also, the markdown file must have the table schema formatted at the end of the file with markdown bullet points, as follows:\n",
    "\n",
    "```\n",
    "# Table Schema\n",
    " - field_1: \n",
    " - field_2: lots\n",
    " of stuff about field 2\n",
    "   - you can make a list of items for field 2\n",
    "   - if you indent them\n",
    " - field_3: it is important to have the :\n",
    " \n",
    " this will also be in field 3\n",
    " \n",
    " - field_4: this is in the 4th field\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from subprocess import check_output\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_markdownify(text):\n",
    "    '''this gets rid of # characters, and also [ and ]. Can be improved'''\n",
    "    return text.replace(\"# \",\"\").replace(\"#\",\"\").replace(\"[\",\"\").replace(\"]\",\" \")\n",
    "\n",
    "def push_readme_to_gcs(table):\n",
    "    with open(\"{}.md\".format(table),'rU') as f:\n",
    "        lines = f.read()\n",
    "    # getting rid of the \"#\", and other formatting, and push to gcs\n",
    "    lines2 = de_markdownify(lines)\n",
    "    with open(\"temp.txt\", 'w') as f:\n",
    "        f.write(lines2)    \n",
    "    command = 'gsutil cp temp.txt gs://global_footprint_of_fisheries/{}/readme.txt'.format(table)\n",
    "    os.system(command)\n",
    "    os.system(\"rm temp.txt\")\n",
    "\n",
    "def add_documentation_to_bigquery(table):\n",
    "    \n",
    "    '''this takes a markdown file at TABLE_NAME.md and loads\n",
    "    it into a bigquery table, with the same name, at '''\n",
    "    \n",
    "    with open(\"{}.md\".format(table),'rU') as f:\n",
    "        lines = f.read()\n",
    "    # getting rid of the \"#\", and other formatting, and push to gcs\n",
    "    lines = de_markdownify(lines)\n",
    "    \n",
    "    # this assumes that the file is divided into a line that equals Schema\\n\n",
    "    table_description = lines.split(\"\\nTable Schema\\n\")[0]\n",
    "    table_schema = lines.split(\"\\nTable Schema\\n\")[1]\n",
    "    # add description\n",
    "    table_description = table_description.replace(\"'\",\"'\\\\''\").replace('\"',\"\"\"'\\\\\"'\"\"\") # so the command works\n",
    "    command = '''bq update --description '{table_description}'\\\n",
    "     global-fishing-watch:global_footprint_of_fisheries.{table}'''.format(table_description=table_description,\n",
    "                                                                         table=table)\n",
    "    os.system(command)\n",
    "    \n",
    "    # add schema\n",
    "    add_schema(table, table_schema)\n",
    "\n",
    "    \n",
    "def add_schema(table, table_schema):\n",
    "    '''takes a table, and a table_schema which is written as a list in markdown, and loads \n",
    "    the values into the table on bigquery. The fields in the list have to match perfectly with \n",
    "    the fields in the existing bigquery table, or this will fail.'''\n",
    "    descriptions = {}\n",
    "\n",
    "    for line in table_schema[3:].split(\"\\n - \"):\n",
    "        if(\":\" in line): \n",
    "            k = line.split(\":\")[0]\n",
    "            value = \"\".join(line.split(\":\")[1:])\n",
    "            descriptions[k]=value\n",
    "    \n",
    "    # Get the existing bigquery schema\n",
    "    command = \"bq show --format=json global-fishing-watch:global_footprint_of_fisheries.{table}\".format(table=table)\n",
    "    out = check_output(command.split(\" \"))\n",
    "\n",
    "    # update the schema structure to include a description from the markdown file\n",
    "    j = json.loads(out)\n",
    "    for i, s in enumerate(j['schema']['fields']):\n",
    "        d = descriptions[s['name']]\n",
    "        j['schema']['fields'][i]['description'] = d\n",
    "\n",
    "    # load this new schema into bigquery\n",
    "    with open('temp.json','w') as f:\n",
    "        f.write(json.dumps(j['schema']['fields']))\n",
    "    command = \"bq update global-fishing-watch:global_footprint_of_fisheries.{table} temp.json\".format(table=table)\n",
    "    os.system(command)\n",
    "    os.system(\"rm -f temp.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = 'fishing_effort'\n",
    "add_documentation_to_bigquery(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "push_readme_to_gcs(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "onlyfiles = [f for f in listdir(\"./\") if isfile(join(\"./\", f))]\n",
    "for o in onlyfiles:\n",
    "    if len(o)>3 and o[-3:] == \".md\": \n",
    "        table = o[:-3]\n",
    "        add_documentation_to_bigquery(table)       \n",
    "        push_readme_to_gcs(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
